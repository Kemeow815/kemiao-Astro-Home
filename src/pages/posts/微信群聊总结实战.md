---
layout: "../../layouts/BlogPost.astro"
title: "微信群聊总结实战"
description: "远离微信开发，会变得不幸"
pubDate: "2025-06-15 11:00:00"
heroImage: "/public/assets/imgs/b19eecb79031fa33bdd897779ee5563aac4fb479cd570c5c6f0ac7ecb438dfca.png"
---

> 远离微信开发，会变得不幸

# 背景

作为和微信开发相爱相杀多年的开发者来说，不得不说请大家谨记开头这句话，不得不的情况下，千万别开发，请把生命浪费在美好的事情上😢

最近读书群三周年了，打算总结下群内大家的发言，目标是为大家制作类似网易云音乐的年度总结，群内的分享记录，能反映出大家生活状态的方方面面，还是非常有价值和纪念意义的，在折腾了一段时间之后，完成了活动总结的页面，跟大家分享下调研的一些发现


# 调研

看了一圈，开源方案主要有以下几个：

1. [chatlog](https://github.com/sjzar/chatlog)
   1. 状态：不再维护
   2. 代码：依然可用，但仅在 3.x 微信版本上可用
   3. 特点：支持 mcp/http 服务获取聊天数据
2. [WechatMsg](https://github.com/LC044/WeChatMsg)
   1. 状态：不再维护
   2. 代码：已清空
   3. 特点：功能简单+强大（[bilibili 演示](https://www.bilibili.com/video/BV1korAYdEwm/?spm_id_from=..search-card.all.click&vd_source=366bb414305b3c2d4d8fdefe5b587d14)）
   4. 说明：点赞量非常高的 repo，在被请喝茶后清空了 repo，已经无法使用
3. [WechatExporter](https://github.com/BlueMatthew/WechatExporter)
   1. 状态：不再维护
   2. 代码：未尝试，新版本从 issues 中分析，已经不使用
   3. 特点：完整导出所有聊天内容，完整性强
   4. 说明：在被请喝茶后清空了 repo，已经无法使用
4. [WeChatFerry](https://github.com/lich0821/WeChatFerry)
   1. 状态：不再维护
   2. 代码：已清空
   3. 特点：hook 微信进程，解析消息接发过程，可以进行新消息的转存和记录
   2. 说明：在被请喝茶后清空了 repo，已经无法使用
5. [wechatDataBackup](https://github.com/git-jiadong/wechatDataBackup)
   1. 状态：应该还在维护中
   2. 代码：猜测可用，未完整测试
   3. 特点：解密 db 后存储在本地，备份后可自由查看
6. [cloudbak](https://github.com/likeflyme/cloudbak?tab=readme-ov-file)
   1. 状态：应该还在维护中
   2. 代码：猜测可用，未测试
   3. 特点：通过客户端传输至本地服务，进行解密备份，备份后可自由查看

上面的方案，chatlog 和 WechatExporter 是支持 MacOS 的，其他的都在 Windows 上才可完成，考虑 MacOS 基本都得关 SIP，并且稳定性不好说，下文默认都是 Windows 环境下的操作

# 方案

总的来说，完成目标大概分几步：

1. 获取聊天数据
2. 进行数据校验与清洗
3. 制定活动目标关键词提取模板
4. 完成关键数据格式化
5. 制作活动页面
6. 活动页面优化

获取聊天数据其实是最难的一步，占任务量的 40% 吧，可以通过上面的各种集成方案解决，或者动手能力强的话，可以直接找解密本地微信 db 的 repo 尝试，如[PyWxDump](https://github.com/xaoyaoo/PyWxDump/tree/master)

这里因为时间有限，我选择了第一个跑通的方案，就是 chatlog，本身支持 mcp 的方式，明显降低了后续可能的开发成本，下面说下详细步骤

# 步骤

## 获取数据

chatlog 因为不再维护的问题，目前并不支持最新版本的微信，所以第一步就是找到正确的微信版本安装，并且关闭自动更新，可以在这个 repo 中寻找 [wechat-windows-versions](https://github.com/tom-snow/wechat-windows-versions/releases)，chatlog 的可用版本见这个 [issue](https://github.com/sjzar/chatlog/issues/131)，感谢所有用爱发电的技术大佬

正常操作之后，目前已经完成解密和服务器的启动了。这里我获取了下群内最近一年的所有数据，发现返回速度比想象中的快不少，大概也就 1s 就完成了

![picture 3](/assets/imgs/d1c3b346b2405899756d70e10adb42d0a1cb1aec3524df9171f47598f8bf1ef3.png)  


## 数据准备

获取的微信原始数据，大量引用类的内容没有做二次解析，大量的图片和引用二链接信息，就都没有统计到这次的内容中

![picture 4](/assets/imgs/15e594f002813c055faae1c39e303cbca1a3b41752a10c6b19becc51de9f9766.png)  

除此之外，每个月阅读计划中的接龙信息，还有用户名中的一些书籍信息，由于反复出现，会被统计到内容到中，这块都需要在数据处理时做一些定制化的筛选

清理完之后，最后的数据类似如下内容

![picture 5](/assets/imgs/1768415ee01dc3db640891735236f15bf157e4f5302c893184e39c209bb85e63.png)  

之后，需要把原始文本，通过 gpt 格式化成后续应用需要使用的格式，这块使用 germini 2.5 pro 完成的，对比了很多模型，它的整体的生成效果和能力还是比较 ok 的

![picture 6](/assets/imgs/ca7404e0e970ab50d33251ae65729161cb233f15d46dd39178e4c8b8e4e72981.png)  

## 页面制作

页面制作应该算是最简单的一步，这块制定好需要的页面功能之后，通过 claude 4 跑一版，基本上就可以完成功能的使用

后续对内容进行一些定制性的调整和优化，基本上就可以使用了，需要注意一点，在页面开发前最好吧数据完整处理完毕，避免在开发的时候再次反复做数据源的格式化。在大量数据的情况下，cursor 是没法直接快速完成，完整数据的清洗的优化的

## 部署上线

通过我的 cdn 直接完成 build 上传即可

# 总结

> 成品如下，大家感兴趣的话，欢迎查看读书群的总结界面：[URL](https://blog.peterchen97.cn/2025/index.html)

整体来说应该花费了 4h 以上的时间，来处理获得这个不太完美的总结页面。从效果来说，还是有很多值得优化的地方的；从效率来说，这个效率是极低的，相对 tg 的软件开发来说，简直就是浪费生命

但不得不说，作为国内的应用来说，不得不对这些严防死守，在如此大的用户量之下，用户信息安全的保障优先级远大于开发者体验，毕竟是一个 “小而美” 的软件，不能面面俱到，对吧🐶

希望感兴趣的朋友，可以动手尝试一下，可能发现很多意想不到的数据哈哈哈

![picture 2](/assets/imgs/8063526783f612d750d15569b314a4e51d713c2d68d200edc6477b776cf7d097.png)  
